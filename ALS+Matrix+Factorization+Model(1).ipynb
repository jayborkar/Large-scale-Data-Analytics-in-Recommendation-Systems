{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local\").setAppName(\"My App\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"Workplace/Data Mining/Digital_Music_5.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "musint = sqlContext.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64706"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musint.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(musint.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asin',\n",
       " 'helpful',\n",
       " 'overall',\n",
       " 'reviewText',\n",
       " 'reviewTime',\n",
       " 'reviewerID',\n",
       " 'reviewerName',\n",
       " 'summary',\n",
       " 'unixReviewTime']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musint.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3568"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musint.select('asin').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of reviewers or users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5541"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musint.select('reviewerID').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "musint=musint.select([\"asin\",\"overall\",\"reviewerID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------+\n",
      "|      asin|overall|    reviewerID|\n",
      "+----------+-------+--------------+\n",
      "|5555991584|    5.0|A3EBHHCZO6V2A4|\n",
      "|5555991584|    5.0| AZPWAXJG9OJXV|\n",
      "|5555991584|    5.0|A38IRL0X2T4DPF|\n",
      "|5555991584|    5.0|A22IK3I6U76GX0|\n",
      "|5555991584|    4.0|A1AISPOIIHTHXX|\n",
      "|5555991584|    5.0|A2P49WD75WHAG5|\n",
      "|5555991584|    3.0|A3O90G1D7I5EGG|\n",
      "|5555991584|    5.0|A3EJYJC25OJVKK|\n",
      "|5555991584|    5.0|A1DA8VOH9NR6C7|\n",
      "|5555991584|    5.0|A33TRNCQK4IUO7|\n",
      "|5555991584|    5.0| AWY3EPKEOUV1W|\n",
      "|5555991584|    4.0|A1SCJWCMQ3W3KK|\n",
      "|5555991584|    5.0|A14BTJRH9VNLJJ|\n",
      "|5555991584|    5.0|A2AOZQ3WTNVVOK|\n",
      "|5555991584|    4.0|A1BXA3SM3AJOKL|\n",
      "|5555991584|    5.0|A3CCYAQRHUTPIQ|\n",
      "|5555991584|    5.0| AHUT55E980RDR|\n",
      "|5555991584|    5.0|A24N1BAS3CU27H|\n",
      "|5555991584|    4.0|A19YHEBK099R7U|\n",
      "|5555991584|    5.0|A16KCH578FG4B4|\n",
      "+----------+-------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "musint.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to convert alphanumeric ids to integer type ids\n",
    "def modify_ids(sample):\n",
    "    i = 0\n",
    "    user_map = {}\n",
    "    for user in sample:\n",
    "        if user in user_map.keys():\n",
    "            pass\n",
    "        else:\n",
    "            i = i + 1\n",
    "            user_map[user] = i\n",
    "            \n",
    "    return user_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr1 = musint.select('asin').distinct().rdd.map(lambda r: r[0]).collect()\n",
    "arr2 = musint.select('reviewerID').distinct().rdd.map(lambda r:r[0]).collect()\n",
    "dicti1 = modify_ids(arr1)\n",
    "dicti2 = modify_ids(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def translate(mapping):\n",
    "    def translate_(col):\n",
    "        return mapping.get(col)\n",
    "    return udf(translate_, IntegerType())\n",
    "\n",
    "musint = musint.withColumn(\"product_id\", translate(dicti1)(\"asin\"))\n",
    "musint = musint.withColumn(\"reviewer_id\", translate(dicti2)(\"reviewerID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a new column rating by converting overall column to float type\n",
    "from pyspark.sql.types import FloatType\n",
    "musint=musint.withColumn(\"rating\", musint[\"overall\"].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "musint=musint.drop(*['asin','reviewerID','overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+------+\n",
      "|product_id|reviewer_id|rating|\n",
      "+----------+-----------+------+\n",
      "|      2421|       4724|   5.0|\n",
      "|      2421|       4756|   5.0|\n",
      "|      2421|       3339|   5.0|\n",
      "|      2421|        353|   5.0|\n",
      "|      2421|       4631|   4.0|\n",
      "|      2421|       4430|   5.0|\n",
      "|      2421|       3851|   3.0|\n",
      "|      2421|       2682|   5.0|\n",
      "|      2421|       4910|   5.0|\n",
      "|      2421|       1426|   5.0|\n",
      "|      2421|       1399|   5.0|\n",
      "|      2421|       2821|   4.0|\n",
      "|      2421|       2741|   5.0|\n",
      "|      2421|       3453|   5.0|\n",
      "|      2421|       1699|   4.0|\n",
      "|      2421|       1865|   5.0|\n",
      "|      2421|       3884|   5.0|\n",
      "|      2421|       2043|   5.0|\n",
      "|      2421|       2852|   4.0|\n",
      "|      2421|       2529|   5.0|\n",
      "+----------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "musint.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "\n",
    "(training,test) = musint.randomSplit([0.8, 0.2])\n",
    "\n",
    "#als = ALS(userCol = \"reviewer_id\",itemCol=\"product_id\", ratingCol=\"rating\",coldStartStrategy = \"drop\",nonnegative = True)\n",
    "als = ALS(maxIter=20, regParam=0.2, rank = 80, userCol=\"reviewer_id\", itemCol=\"product_id\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\", nonnegative=True)\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best model we got with maximum iterations 20, rank = 80 and regularization parameter = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.9987045802088677\n",
      "Mean Absolute error = 0.7905045967999144\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "evaluator1 = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "evaluator2 = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "rmse = evaluator1.evaluate(predictions)\n",
    "mae = evaluator2.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "print(\"Mean Absolute error = \" + str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "# top 20 recommendations overall based on products rated say, above 100 times.\n",
    "ratedMost = training.groupBy('product_id').count().filter(\"count > 100\").sort(desc(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ratedMost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|product_id|count|\n",
      "+----------+-----+\n",
      "|       367|  211|\n",
      "|       323|  210|\n",
      "|      2519|  160|\n",
      "|       863|  151|\n",
      "|      1365|  146|\n",
      "|      1017|  144|\n",
      "|      2091|  144|\n",
      "|      1672|  138|\n",
      "|      3053|  132|\n",
      "|       448|  131|\n",
      "|      3211|  129|\n",
      "|      2560|  128|\n",
      "|      1731|  123|\n",
      "|      2779|  123|\n",
      "|       104|  119|\n",
      "|      2273|  113|\n",
      "|      2871|  112|\n",
      "|      2461|  111|\n",
      "|       200|  107|\n",
      "|      2388|  107|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratedMost.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratedMost.count()\n",
    "# there are 22 products rated more than 100 times, out of which we select top 10 to be recommended to all customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(product_id=367, count=211),\n",
       " Row(product_id=323, count=210),\n",
       " Row(product_id=2519, count=160),\n",
       " Row(product_id=863, count=151),\n",
       " Row(product_id=1365, count=146),\n",
       " Row(product_id=2091, count=144),\n",
       " Row(product_id=1017, count=144),\n",
       " Row(product_id=1672, count=138),\n",
       " Row(product_id=3053, count=132),\n",
       " Row(product_id=448, count=131)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 recommendations alongwith Ratings\n",
    "ratedMost.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "predictions = predictions.withColumn(\"round_prediction\",func.round(predictions[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+------+----------+----------------+\n",
      "|product_id|reviewer_id|rating|prediction|round_prediction|\n",
      "+----------+-----------+------+----------+----------------+\n",
      "|       148|       1507|   5.0|  4.795439|             5.0|\n",
      "|       148|        808|   5.0| 4.0881286|             4.0|\n",
      "|       148|       4408|   5.0|  4.877437|             5.0|\n",
      "|       148|       3010|   5.0| 4.1411295|             4.0|\n",
      "|       148|       1588|   3.0| 3.2804918|             3.0|\n",
      "|       148|       2549|   5.0| 4.8106055|             5.0|\n",
      "|       148|       2882|   4.0|  4.481371|             4.0|\n",
      "|       148|       1902|   4.0|  3.920722|             4.0|\n",
      "|       148|       2210|   5.0|  4.823954|             5.0|\n",
      "|       148|       1275|   5.0|  4.403393|             4.0|\n",
      "|       148|       3209|   5.0| 4.8427114|             5.0|\n",
      "|       148|       3757|   5.0| 4.9464245|             5.0|\n",
      "|       148|       2994|   5.0|  4.697911|             5.0|\n",
      "|       148|       2968|   5.0|  4.754431|             5.0|\n",
      "|       148|        423|   5.0| 4.8129773|             5.0|\n",
      "|       148|       1066|   5.0| 5.0127106|             5.0|\n",
      "|       148|       1717|   5.0| 4.8068914|             5.0|\n",
      "|       148|       4436|   5.0| 4.4395285|             4.0|\n",
      "|       148|       1876|   5.0| 4.6553555|             5.0|\n",
      "|       148|       2172|   5.0|  4.243454|             4.0|\n",
      "+----------+-----------+------+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.6596418459335643\n",
      "Mean Absolute error = 0.36278904414492397\n"
     ]
    }
   ],
   "source": [
    "# checked for rounded values of prediction column\n",
    "evaluator1 = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"round_prediction\")\n",
    "evaluator2 = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\",predictionCol=\"round_prediction\")\n",
    "rmse = evaluator1.evaluate(predictions)\n",
    "mae = evaluator2.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "print(\"Mean Absolute error = \" + str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|reviewer_id|     recommendations|\n",
      "+-----------+--------------------+\n",
      "|       1580|[[2637, 5.194005]...|\n",
      "|       4900|[[2143, 5.273694]...|\n",
      "|       5300|[[3341, 4.46827],...|\n",
      "|        471|[[1113, 4.589177]...|\n",
      "|       1591|[[1358, 4.6457696...|\n",
      "|       4101|[[2599, 4.9881334...|\n",
      "|       1342|[[1113, 5.2407956...|\n",
      "|       2122|[[1957, 4.731841]...|\n",
      "|       2142|[[153, 5.0766716]...|\n",
      "|        463|[[1524, 4.639947]...|\n",
      "|        833|[[1185, 4.0442247...|\n",
      "|       3794|[[2637, 5.2714286...|\n",
      "|       1645|[[1113, 5.224621]...|\n",
      "|       3175|[[2599, 4.0874147...|\n",
      "|       4935|[[1547, 4.4668393...|\n",
      "|        496|[[337, 3.3820245]...|\n",
      "|       2366|[[1223, 4.3924766...|\n",
      "|       2866|[[376, 4.4811306]...|\n",
      "|       5156|[[583, 4.9026413]...|\n",
      "|       3997|[[1113, 5.005373]...|\n",
      "+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.recommendForAllUsers(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct\n",
    "predictions2=predictions.withColumn(\"pred_tuple\",struct(predictions.round_prediction,predictions.rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = predictions2.select('pred_tuple').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = sc.parallelize(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = MulticlassMetrics(predictionAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# implementing it on the complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.app.id=local-1525620598384\n",
      "spark.app.name=My App\n",
      "spark.driver.host=SpectreX.home\n",
      "spark.driver.port=37337\n",
      "spark.executor.id=driver\n",
      "spark.master=local\n",
      "spark.rdd.compress=True\n",
      "spark.serializer.objectStreamReset=100\n",
      "spark.submit.deployMode=client\n",
      "spark.ui.showConsoleProgress=true\n"
     ]
    }
   ],
   "source": [
    "print (sc.getConf().toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|rating|count|\n",
      "+------+-----+\n",
      "|   5.0|35580|\n",
      "|   2.0| 3010|\n",
      "|   3.0| 6789|\n",
      "|   1.0| 2791|\n",
      "|   4.0|16536|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "musint.groupBy('rating').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision = metrics.precision()\n",
    "recall = metrics.recall()\n",
    "f1Score = metrics.fMeasure()\n",
    "print(\"Precision = %s\" % precision)\n",
    "print(\"Recall = %s\" % recall)\n",
    "print(\"F1 Score = %s\" % f1Score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
